{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RETRIEVAL AUGMENTED GENERATION - Youtube\n",
    "\n",
    "Exemple de RAG basé sur des vidéos Youtube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prérequis\n",
    "\n",
    "Installer ffmpeg et l'ajouter au path de la machine\n",
    "\n",
    "```bash\n",
    "sudo apt update && sudo apt upgrade\n",
    "sudo apt install ffmpeg\n",
    "export PATH=$PATH:/usr/bin/ffmpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load\n",
    "\n",
    "Le chargement des sources se fait exactement de la même manière que pour des documents texte. \n",
    "\n",
    "Nous utilisons simplement un loader adapté à notre source, ici une combinaison de `YoutubeAudioLoader` pour le téléchargement de la piste audio des vidéos et `OpenAIWhisperer` pour la transcription audio => texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_community.document_loaders.blob_loaders.youtube_audio import (\n",
    "    YoutubeAudioLoader,\n",
    ")\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers.audio import OpenAIWhisperParser\n",
    "\n",
    "# URLS of target videos\n",
    "urls = [\"https://youtu.be/3caCwH2MSIk\", \"https://youtu.be/JlodpOubfqE\"]\n",
    "\n",
    "#LOAD\n",
    "loader = GenericLoader(YoutubeAudioLoader(urls, \"../__downloads__\"), OpenAIWhisperParser())\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split | Embed | Store\n",
    "\n",
    "La partie split/embed/store est-elle rigoureusement la même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.redis import Redis\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "#SPLIT\n",
    "combined_docs = [doc.page_content for doc in docs]\n",
    "text = \" \".join(combined_docs)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n",
    "splits = text_splitter.split_text(text)\n",
    "\n",
    "#EMBED & STORE\n",
    "vectorstore = Redis.from_texts(\n",
    "    splits,\n",
    "    OpenAIEmbeddings(),\n",
    "    redis_url=os.getenv(\"REDIS_URL\"),\n",
    "    index_name=\"genai_in_action_youtube_rag\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chaîne finale\n",
    "\n",
    "De la même manière la chaîne ne change pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI, ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "  (\"human\", \n",
    "   \"\"\"You are an assistant for question-answering tasks about  a company named Younup. \n",
    "   Use the following pieces of retrieved context to answer the question. \n",
    "   If you don't know the answer, just say that you don't know.\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\"\"\"\n",
    "    ))\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_chain = rag_chain = (\n",
    "    # Runnable parallèles\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | vectorstore.as_retriever() | format_docs, \n",
    "        \"question\": itemgetter(\"question\"), \n",
    "        \"history\": itemgetter(\"history\")\n",
    "    }\n",
    "    # Runnable séquentiels\n",
    "    | prompt\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question!\n",
    "question = \"Quelle est la principale fièrté de Younup ?\"\n",
    "qa_chain.invoke({\n",
    "    \"question\":question, \n",
    "    \"history\": [] \n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
