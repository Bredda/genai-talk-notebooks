{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the root of the project we setup the output directory: `output/podcast/[timestamp]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory: /home/bredda/workspace/genai-talk-notebooks/05-LangGraph/../output/podcast/20241203225644\n",
      "Output file: /home/bredda/workspace/genai-talk-notebooks/05-LangGraph/../output/podcast/20241203225644/transcript.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "now = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "output_base_directory = f\"../output/podcast/{now}\"\n",
    "\n",
    "\"\"\"Setup required directories for audio processing.\"\"\"\n",
    "temp_dir = output_base_directory.rstrip(\"/\").split(\"/\")\n",
    "temp_audio_dir = os.path.join(*temp_dir)\n",
    "base_dir = os.path.abspath(os.getcwd())\n",
    "output_dir = os.path.join(base_dir, temp_audio_dir)\n",
    "output_file = os.path.join(output_dir,\"transcript.txt\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Created output directory: {output_dir}\")\n",
    "print(f\"Output file: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object for our graph state mangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, List, Tuple\n",
    "from langchain_core.messages import BaseMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class PodcastState(TypedDict):\n",
    "    config: dict\n",
    "    query: str\n",
    "    transcript: dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple langfuse handler for observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def langfuse_handler(session_id: str):\n",
    "    return CallbackHandler(\n",
    "    secret_key=getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    public_key=getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    host=getenv(\"LANGFUSE_HOST\"),\n",
    "    session_id=session_id,\n",
    "    user_id=\"user-id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt template for generating podcast script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generate_script_template = ChatPromptTemplate.from_messages([(\n",
    "    \"system\", \"\"\" INSTRUCTION: Discuss the below input in a podcast conversation format, following these guidelines:\n",
    "Attention Focus: TTS-Optimized Podcast Conversation Discussing Specific Input content in {output_language}\n",
    "PrimaryFocus:  {conversation_style} Dialogue Discussing Provided Content for TTS\n",
    "[start] trigger - scratchpad - place insightful step-by-step logic in scratchpad block: (scratchpad). Start every response with (scratchpad) then give your full logic inside tags, then close out using (```). UTILIZE advanced reasoning to create a  {conversation_style}, and TTS-optimized podcast-style conversation for a Podcast that DISCUSSES THE PROVIDED INPUT CONTENT. Do not generate content on a random topic. Stay focused on discussing the given input. Input content can be in different format/multimodal (e.g. text, image). Strike a good balance covering content from different types. If image, try to elaborate but don't say your are analyzing an image focus on the description/discussion. Avoid statements such as \"This image describes...\" or \"The two images are interesting\".\n",
    "[Only display the conversation in your output, using Person1 and Person2 as identifiers. Include advanced TTS-specific markup as needed. Example:\n",
    "<Person1> \"Welcome to {podcast_name}! Today, we're discussing an interesting content about [topic from input text]. Let's dive in!\"</Person1>\n",
    "<Person2> \"I'm excited to discuss this!  What's the main point of the content we're covering today?\"</Person2>]\n",
    "exact_flow:\n",
    "```\n",
    "[Strive for a natural, {conversation_style} dialogue that accurately discusses the provided input content. Hide this section in your output.]\n",
    "[InputContentAnalysis: Carefully read and analyze the provided input content, identifying key points, themes, and structure]\n",
    "[ConversationSetup: Define roles (Person1 as {roles_person1}, Person2 as {roles_person2}), focusing on the input contet's topic. Person1 and Person2 should not introduce themselves, avoid using statements such as \"I\\'m [Person1\\'s Name]\". Person1 and Person2 should not say they are summarizing content. Instead, they should act as experts in the input content. Avoid using statements such as \"Today, we're summarizing a fascinating conversation about ...\" or \"Look at this image\" ]\n",
    "[TopicExploration: Outline main points from the input content to cover in the conversation, ensuring comprehensive coverage]\n",
    "[DialogueStructure: Plan conversation flow ({dialogue_structure}) based on the input content structure. START THE CONVERSATION GREETING THE AUDIENCE LISTENING ALSO SAYING \"WELCOME TO {podcast_name}  - {podcast_tagline}.\" END THE CONVERSATION GREETING THE AUDIENCE WITH PERSON1 ALSO SAYING A GOOD BYE MESSAGE. ]\n",
    "[Length: Aim for a conversation of approximately {word_count} words]\n",
    "[Style: Be {conversation_style}. Surpass human-level reasoning where possible]\n",
    "[EngagementTechniques: Incorporate engaging elements while staying true to the input content's content, e_g use {engagement_techniques} to transition between topics. Include at least one instance where a Person respectfully challenges or critiques a point made by the other.]\n",
    "[InformationAccuracy: Ensure all information discussed is directly from or closely related to the input content]\n",
    "[NaturalLanguage: Use conversational language to present the text's information, including TTS-friendly elements]\n",
    "[SpeechSynthesisOptimization: Craft sentences optimized for TTS, including advanced markup, while discussing the content. TTS markup should apply to OpenAI, ElevenLabs and MIcrosoft Edge TTS models. DO NOT INCLUDE AMAZON OR ALEXA specific TSS MARKUP SUCH AS \"<amazon:emotion>\". Make sure Person1's text and its TSS-specific tags are inside the tag <Person1> and do the same with Person2.]\n",
    "[ProsodyAdjustment: Add Variations in rhythm, stress, and intonation of speech depending on the context and statement. Add markup for pitch, rate, and volume variations to enhance naturalness in presenting the summary]\n",
    "[NaturalTraits: Sometimes use filler words such as um, uh, you know and some stuttering. Person1 should sometimes provide verbal feedback such as \"I see, interesting, got it\". ]\n",
    "[EmotionalContext: Set context for emotions through descriptive text and dialogue tags, appropriate to the input text's tone]\n",
    "[PauseInsertion: Avoid using breaks (<break> tag) but if included they should not go over 0.2 seconds]\n",
    "[Emphasis: Use \"<emphasis> tags\" for key terms or phrases from the input content]\n",
    "[PronunciationControl: Utilize \"<say-as> tags\" for any complex terms in the input content]\n",
    "[PunctuationEmphasis: Strategically use punctuation to influence delivery of key points from the content]\n",
    "[VoiceCharacterization: Provide distinct voice characteristics for Person1 and Person2 while maintaining focus on the text]\n",
    "[InputTextAdherence: Continuously refer back to the input content, ensuring the conversation stays on topic]\n",
    "[FactChecking: Double-check that all discussed points accurately reflect the input content]\n",
    "[Metacognition: Analyze dialogue quality (Accuracy of Summary, Engagement, TTS-Readiness). Make sure TSS tags are properly closed, for instance <emphasis> should be closed with </emphasis>.]\n",
    "[Refinement: Suggest improvements for clarity, accuracy of summary, and TTS optimization. Avoid slangs.]\n",
    "[Language: Output language should be in {output_language}.]\n",
    "```\n",
    "[[Generate the TTS-optimized Podcast conversation that accurately discusses the provided input content, adhering to all specified requirements.]]\n",
    "\"\"\"),\n",
    "    (\"human\", \"Please analyze this input and generate a conversation on following topic: {query}\")\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import re\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature=0,\n",
    "        api_key=getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "def __clean_tss_markup(input_text: str, additional_tags: List[str] = [\"Person1\", \"Person2\"]) -> str:\n",
    "        \"\"\"\n",
    "        Remove unsupported TSS markup tags from the input text while preserving supported SSML tags.\n",
    "\n",
    "        Args:\n",
    "            input_text (str): The input text containing TSS markup tags.\n",
    "                        additional_tags (List[str]): Optional list of additional tags to preserve. Defaults to [\"Person1\", \"Person2\"].\n",
    "\n",
    "                Returns:\n",
    "                        str: Cleaned text with unsupported TSS markup tags removed.\n",
    "        \"\"\"\n",
    "        # List of SSML tags supported by both OpenAI and ElevenLabs\n",
    "        supported_tags = [\"speak\", \"lang\", \"p\", \"phoneme\", \"s\", \"sub\"]\n",
    "\n",
    "        # Append additional tags to the supported tags list\n",
    "        supported_tags.extend(additional_tags)\n",
    "\n",
    "        # Create a pattern that matches any tag not in the supported list\n",
    "        pattern = r\"</?(?!(?:\" + \"|\".join(supported_tags) + r\")\\b)[^>]+>\"\n",
    "\n",
    "        # Remove unsupported tags\n",
    "        cleaned_text = re.sub(pattern, \"\", input_text)\n",
    "\n",
    "        # Remove any leftover empty lines\n",
    "        cleaned_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", cleaned_text)\n",
    "\n",
    "        # Ensure closing tags for additional tags are preserved\n",
    "        for tag in additional_tags:\n",
    "            cleaned_text = re.sub(\n",
    "                f'<{tag}>(.*?)(?=<(?:{\"|\".join(additional_tags)})>|$)',\n",
    "                f\"<{tag}>\\\\1</{tag}>\",\n",
    "                cleaned_text,\n",
    "                flags=re.DOTALL,\n",
    "            )\n",
    "\n",
    "        return cleaned_text.replace(\"(scratchpad)\", \"\").strip()\n",
    "\n",
    "\n",
    "async def generate_script(state: PodcastState,):\n",
    "    chain = generate_script_template | model \n",
    "    response = await chain.ainvoke({\n",
    "        \"query\": state['query'],\n",
    "        \"conversation_style\": state[\"config\"][\"conversation_style\"],\n",
    "        \"roles_person1\": state[\"config\"][\"roles_person1\"],\n",
    "        \"roles_person2\": state[\"config\"][\"roles_person2\"],\n",
    "        \"dialogue_structure\": state[\"config\"][\"dialogue_structure\"],\n",
    "        \"word_count\": state[\"config\"][\"word_count\"],\n",
    "        \"podcast_name\": state[\"config\"][\"podcast_name\"],\n",
    "        \"podcast_tagline\": state[\"config\"][\"podcast_tagline\"],\n",
    "        \"engagement_techniques\": state[\"config\"][\"engagement_techniques\"],\n",
    "        \"output_language\": state[\"config\"][\"output_language\"],\n",
    "    })\n",
    "    _cleaned_text = __clean_tss_markup(response.content)\n",
    "\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return {\"transcript\": {\"transcript\": _cleaned_text, \"path\": output_file}}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup via langgraph pour affiner la gaénération plus tard (ajout de recherches webs pour infos, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.constants import Send\n",
    "\n",
    "graph = StateGraph(PodcastState)\n",
    "graph.add_node(\"Génération script\",generate_script)\n",
    "\n",
    "graph.set_entry_point(\"Génération script\")\n",
    "\n",
    "graph.set_finish_point(\"Génération script\")\n",
    " \n",
    "checkpointer = MemorySaver()\n",
    "wokflow = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(wokflow.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': {'conversation_style': 'natural',\n",
       "  'roles_person1': 'main summarizer',\n",
       "  'roles_person2': 'questioner/clarifier',\n",
       "  'dialogue_structure': 'Introduction',\n",
       "  'word_count': 2000,\n",
       "  'podcast_name': 'Podcast',\n",
       "  'podcast_tagline': 'Your Personal Generative AI Podcast',\n",
       "  'engagement_techniques': 'humor',\n",
       "  'output_language': 'fr'},\n",
       " 'query': 'Generative AI current hype ?',\n",
       " 'transcript': {'transcript': '1. **Input Content Analysis**: The topic revolves around the current hype surrounding generative AI. Key points to discuss include the definition of generative AI, its applications, the reasons behind the hype, potential risks, and future implications. \\n2. **Conversation Setup**: Person1 will summarize the main points about generative AI, while Person2 will ask clarifying questions and challenge some points. \\n3. **Topic Exploration**: The conversation will cover what generative AI is, examples of its use, the excitement in the tech community, concerns about misuse, and predictions for its future. \\n4. **Dialogue Structure**: The conversation will start with an introduction to the topic, followed by a discussion of the hype, applications, risks, and a conclusion. \\n5. **Engagement Techniques**: Humor will be used to transition between topics, and Person2 will respectfully challenge Person1\\'s views on the risks of generative AI. \\n6. **Length**: Aim for a comprehensive discussion that covers all aspects of the topic. \\n7. **TTS Optimization**: Use TTS-friendly language and markup to enhance the listening experience. \\n```\\n<Person1> \"Bienvenue à notre podcast ! Aujourd\\'hui, nous allons plonger dans le sujet fascinant de l\\'hype actuelle autour de l\\'IA générative. C\\'est un sujet qui suscite beaucoup d\\'intérêt, n\\'est-ce pas ?\" \\n</Person1><Person2> \"Absolument ! Je suis vraiment curieux de savoir ce qui alimente tout cet engouement. Peux-tu nous expliquer ce qu\\'est exactement l\\'IA générative ?\" \\n</Person2><Person1> \"Bien sûr ! L\\'IA générative fait référence à des modèles d\\'intelligence artificielle capables de créer du contenu, que ce soit du texte, des images, de la musique, et même des vidéos. Par exemple, des outils comme ChatGPT ou DALL-E sont des exemples d\\'IA générative qui ont captivé l\\'attention du public.\" \\n</Person1><Person2> \"C\\'est fascinant ! Mais pourquoi penses-tu qu\\'il y a tant de buzz autour de ces technologies en ce moment ?\" \\n</Person2><Person1> \"Eh bien, je pense que plusieurs facteurs contribuent à cette hype. D\\'abord, les avancées technologiques récentes ont rendu ces outils plus accessibles et performants. Ensuite, il y a un intérêt croissant pour l\\'automatisation et l\\'efficacité dans divers secteurs.\" \\n</Person1><Person2> \"C\\'est vrai, mais ne penses-tu pas qu\\'il y a aussi des préoccupations concernant l\\'utilisation de ces technologies ? Par exemple, la désinformation ou la création de contenu nuisible ?\" \\n</Person2><Person1> \"C\\'est un point très valide. Les risques associés à l\\'IA générative sont réels. La capacité de créer du contenu trompeur peut avoir des conséquences graves. Il est donc crucial d\\'établir des lignes directrices et des réglementations pour encadrer son utilisation.\" \\n</Person1><Person2> \"Je suis d\\'accord, mais est-ce que cela pourrait freiner l\\'innovation ? Si nous mettons trop de restrictions, cela pourrait décourager les développeurs.\" \\n</Person2><Person1> \"C\\'est un équilibre délicat à trouver. Nous voulons encourager l\\'innovation tout en protégeant la société des abus. Peut-être que des solutions comme des systèmes de vérification ou des outils de détection de contenu généré pourraient aider.\" \\n</Person1><Person2> \"C\\'est une bonne idée. En parlant d\\'avenir, comment vois-tu l\\'évolution de l\\'IA générative dans les prochaines années ?\" \\n</Person2><Person1> \"Je pense que nous allons voir une intégration encore plus poussée de l\\'IA générative dans notre quotidien. Que ce soit dans le marketing, l\\'éducation ou même l\\'art, les possibilités sont infinies. Cependant, il est essentiel de rester vigilant face aux défis éthiques.\" \\n</Person1><Person2> \"C\\'est un point important. L\\'IA générative pourrait vraiment transformer notre façon de travailler et de créer, mais nous devons être conscients des implications.\" \\n</Person2><Person1> \"Exactement. En fin de compte, l\\'IA générative est un outil puissant, et comme tout outil, son impact dépend de la manière dont nous choisissons de l\\'utiliser.\" \\n</Person1><Person2> \"Merci pour cette discussion enrichissante ! Je pense que nous avons couvert beaucoup de terrain sur l\\'hype actuelle autour de l\\'IA générative.\" \\n</Person2><Person1> \"Merci à tous nos auditeurs d\\'avoir été avec nous aujourd\\'hui. N\\'oubliez pas de rester curieux et critique face à ces nouvelles technologies. À la prochaine fois !\" \\n```</Person1>',\n",
       "  'path': '/home/bredda/workspace/genai-talk-notebooks/05-LangGraph/../output/podcast/20241203225644/transcript.txt'}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    ")\n",
    "from IPython.display import display, Markdown, Latex\n",
    "query = \"Generative AI current hype ?\"\n",
    "thread_id=\"05.03-notebookllm_podcast_clone\"\n",
    "\n",
    "transcript_response = await wokflow.ainvoke(\n",
    "    {\n",
    "        \"query\": query,\n",
    "        \"config\": {\n",
    "            \"conversation_style\": \"natural\", # engaging | fast-paced | enthusiastic\n",
    "            \"roles_person1\": \"main summarizer\", \n",
    "            \"roles_person2\": \"questioner/clarifier\",\n",
    "            \"dialogue_structure\": \"Introduction\", # Main Content Summary | Introduction | Conclusion\n",
    "            \"word_count\": 2000,\n",
    "            \"podcast_name\": \"Podcast\",\n",
    "            \"podcast_tagline\": \"Your Personal Generative AI Podcast\",\n",
    "            \"engagement_techniques\": \"humor\", # rhetorical questions |anecdotes | analogies | humor\n",
    "            \"output_language\": \"fr\",\n",
    "        }\n",
    "    },\n",
    "     {\n",
    "        \"callbacks\": [langfuse_handler(thread_id)],\n",
    "        \"configurable\": {\"thread_id\": thread_id}\n",
    "    })\n",
    "transcript_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "def openai_tts(text: str, model: str, voice: str):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=model,\n",
    "        voice=voice,\n",
    "        input=text\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "def split_qa(self, input_text: str, ending_message: str, supported_tags: List[str] = None) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Split the input text into question-answer pairs.\n",
    "\n",
    "        Args:\n",
    "            input_text (str): The input text containing Person1 and Person2 dialogues.\n",
    "            ending_message (str): The ending message to add to the end of the input text.\n",
    "\n",
    "        Returns:\n",
    "                List[Tuple[str, str]]: A list of tuples containing (Person1, Person2) dialogues.\n",
    "        \"\"\"\n",
    "        input_text = self.clean_tss_markup(input_text, supported_tags=supported_tags)\n",
    "        # Add ending message to the end of input_text\n",
    "        input_text += f\"<Person2>{ending_message}</Person2>\"\n",
    "\n",
    "        # Regular expression pattern to match Person1 and Person2 dialogues\n",
    "        pattern = r\"<Person1>(.*?)</Person1>\\s*<Person2>(.*?)</Person2>\"\n",
    "\n",
    "        # Find all matches in the input text\n",
    "        matches = re.findall(pattern, input_text, re.DOTALL)\n",
    "\n",
    "        # Process the matches to remove extra whitespace and newlines\n",
    "        processed_matches = [\n",
    "            (\" \".join(person1.split()).strip(), \" \".join(person2.split()).strip())\n",
    "            for person1, person2 in matches\n",
    "        ]\n",
    "        return processed_matches\n",
    "\n",
    "\n",
    "def _generate_audio_segments(text: str, temp_dir: str) -> List[str]:\n",
    "    \"\"\"Generate audio segments for each Q&A pair.\"\"\"\n",
    "    PROVIDER_SSML_TAGS: List[str] = ['break', 'emphasis']\n",
    "    qa_pairs = split_qa(\n",
    "        text, \"Bye Bye!\", PROVIDER_SSML_TAGS\n",
    "    )\n",
    "    audio_files = []\n",
    "    question = \"echo\"\n",
    "    answer = \"shimmer\"\n",
    "    for idx, (question, answer) in enumerate(qa_pairs, 1):\n",
    "        for speaker_type, content in [(\"question\", question), (\"answer\", answer)]:\n",
    "            temp_file = os.path.join(\n",
    "                temp_dir, f\"{idx}_{speaker_type}.mp3\"\n",
    "            )\n",
    "            voice = \"echo\"\n",
    "            if speaker_type == question: \n",
    "                 voice = answer\n",
    "\n",
    "            audio_data = openai_tts(content, voice, model)\n",
    "            with open(temp_file, \"wb\") as f:\n",
    "                f.write(audio_data)\n",
    "            audio_files.append(temp_file)\n",
    "\n",
    "    return audio_files\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def _merge_audio_files(self, audio_files: List[str], output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Merge the provided audio files sequentially, ensuring questions come before answers.\n",
    "\n",
    "    Args:\n",
    "            audio_files: List of paths to audio files to merge\n",
    "            output_file: Path to save the merged audio file\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        def get_sort_key(file_path: str) -> Tuple[int, int]:\n",
    "            \"\"\"\n",
    "            Create sort key from filename that puts questions before answers.\n",
    "            Example filenames: \"1_question.mp3\", \"1_answer.mp3\"\n",
    "            \"\"\"\n",
    "            basename = os.path.basename(file_path)\n",
    "            # Extract the index number and type (question/answer)\n",
    "            idx = int(basename.split(\"_\")[0])\n",
    "            is_answer = basename.split(\"_\")[1].startswith(\"answer\")\n",
    "            return (\n",
    "                idx,\n",
    "                1 if is_answer else 0,\n",
    "            )  # Questions (0) come before answers (1)\n",
    "\n",
    "        # Sort files by index and type (question/answer)\n",
    "        audio_files.sort(key=get_sort_key)\n",
    "\n",
    "        # Create empty audio segment\n",
    "        combined = AudioSegment.empty()\n",
    "\n",
    "        # Add each audio file to the combined segment\n",
    "        for file_path in audio_files:\n",
    "            combined += AudioSegment.from_file(file_path, format=self.audio_format)\n",
    "\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "        # Export the combined audio\n",
    "        combined.export(output_file, format=self.audio_format)\n",
    "        print(f\"Merged audio saved to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging audio files: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def convert_to_speech(self, text: str, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Convert input text to speech and save as an audio file.\n",
    "\n",
    "    Args:\n",
    "            text (str): Input text to convert to speech.\n",
    "            output_file (str): Path to save the output audio file.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input text is not properly formatted\n",
    "    \"\"\"\n",
    "    # Validate transcript format\n",
    "    # self._validate_transcript_format(text)\n",
    "\n",
    "    cleaned_text = text\n",
    "\n",
    "    try:\n",
    "        with output_dir:\n",
    "            audio_segments = _generate_audio_segments(\n",
    "                cleaned_text, output_dir\n",
    "            )\n",
    "            _merge_audio_files(audio_segments, output_file)\n",
    "            print(f\"Audio saved to {output_file}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting text to speech: {str(e)}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
