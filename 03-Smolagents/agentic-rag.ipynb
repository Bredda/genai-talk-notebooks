{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install smolagents pandas langchain langchain-community sentence-transformers faiss-cpu datasets rank_bm25 --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bredda/workspace/genai-talk-notebooks/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 2647/2647 [00:00<00:00, 6264.71 examples/s]\n",
      "Filter: 100%|██████████| 2647/2647 [00:00<00:00, 49027.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")\n",
    "knowledge_base = knowledge_base.filter(lambda row: row[\"source\"].startswith(\"huggingface/transformers\"))\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]})\n",
    "    for doc in knowledge_base\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "docs_processed = text_splitter.split_documents(source_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Uses semantic search to retrieve the parts of transformers documentation that could be most relevant to answer your query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(\n",
    "            docs, k=10\n",
    "        )\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [\n",
    "                f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content\n",
    "                for i, doc in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "retriever_tool = RetrieverTool(docs_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">For a transformers model training, which is slower, the forward or the backward pass?</span>                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mFor a transformers model training, which is slower, the forward or the backward pass?\u001b[0m                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Output message of the LLM:</span> ────────────────────────────────────────────────────────────────────────────────────────\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Thought: To answer this question, I need to retrieve information about the forward and backward passes in the </span><span style=\"background-color: #0d1117\">     </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">context of training a transformers model. I'll use the </span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">`retriever`</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\"> tool to get relevant information from the </span><span style=\"background-color: #0d1117\">      </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">transformers documentation.</span><span style=\"background-color: #0d1117\">                                                                                        </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Code:</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```py</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">forward_pass_info = retriever(query=\"forward pass in transformers model\")</span><span style=\"background-color: #0d1117\">                                          </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">backward_pass_info = retriever(query=\"backward pass in transformers model\")</span><span style=\"background-color: #0d1117\">                                        </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">print(\"Forward pass info:\", forward_pass_info)</span><span style=\"background-color: #0d1117\">                                                                     </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">print(\"Backward pass info:\", backward_pass_info)</span><span style=\"background-color: #0d1117\">                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```&lt;end_code&gt;</span><span style=\"background-color: #0d1117\">                                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mOutput message of the LLM:\u001b[0m ────────────────────────────────────────────────────────────────────────────────────────\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mThought:\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mTo\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23manswer\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mquestion,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mneed\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretrieve\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mabout\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpasses\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23min\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m     \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mcontext\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mof\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtraining\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23ma\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtransformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmodel.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI'll\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23muse\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m`retriever`\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtool\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mget\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mrelevant\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfrom\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m      \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mtransformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mdocumentation.\u001b[0m\u001b[48;2;13;17;23m                                                                                        \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mCode:\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```py\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mforward_pass_info\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m=\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretriever(query=\"forward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23min\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtransformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmodel\")\u001b[0m\u001b[48;2;13;17;23m                                          \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mbackward_pass_info\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m=\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretriever(query=\"backward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23min\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtransformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mmodel\")\u001b[0m\u001b[48;2;13;17;23m                                        \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mprint(\"Forward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minfo:\",\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward_pass_info)\u001b[0m\u001b[48;2;13;17;23m                                                                     \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mprint(\"Backward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minfo:\",\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward_pass_info)\u001b[0m\u001b[48;2;13;17;23m                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```<end_code>\u001b[0m\u001b[48;2;13;17;23m                                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"font-weight: bold\">Executing this code:</span> ──────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">1 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">forward_pass_info </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retriever(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"forward pass in transformers model\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                  </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">2 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">backward_pass_info </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retriever(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"backward pass in transformers model\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">3 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Forward pass info:\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, forward_pass_info)</span><span style=\"background-color: #272822\">                                                             </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">4 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Backward pass info:\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, backward_pass_info)</span><span style=\"background-color: #272822\">                                                           </span> │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ \u001b[1mExecuting this code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m1 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mforward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mforward pass in transformers model\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m2 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbackward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbackward pass in transformers model\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m3 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mForward pass info:\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mforward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m4 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mBackward pass info:\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbackward_pass_info\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "Forward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 1 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 2 =====\n",
       "model_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors=\"pt\")\n",
       "\n",
       "model(**model_inputs)  # forward pass\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "===== Document 3 =====\n",
       "&gt;&gt;&gt; model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-en-ro\")\n",
       "&gt;&gt;&gt; # forward pass\n",
       "&gt;&gt;&gt; model(**inputs)\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "  While generating the target text set the `decoder_start_token_id` to the target language id. The following\n",
       "  example shows how to translate English to Romanian using the *facebook/mbart-large-en-ro* model.\n",
       "\n",
       "```python\n",
       "&gt;&gt;&gt; from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
       "\n",
       "===== Document 4 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 5 =====\n",
       "Next, regarding the debugging strategy, there are generally a few from\n",
       "which to choose from:\n",
       "\n",
       "-   Decompose the original model into many small testable components and\n",
       "    run a forward pass on each of those for verification\n",
       "-   Decompose the original model only into the original *tokenizer* and\n",
       "    the original *model*, run a forward pass on those, and use\n",
       "    intermediate print statements or breakpoints for verification\n",
       "\n",
       "===== Document 6 =====\n",
       "Next, regarding the debugging strategy, there are generally a few from which to choose from:\n",
       "\n",
       "- Decompose the original model into many small testable components and run a forward pass on each of those for\n",
       "  verification\n",
       "- Decompose the original model only into the original *tokenizer* and the original *model*, run a forward pass on\n",
       "  those, and use intermediate print statements or breakpoints for verification\n",
       "\n",
       "===== Document 7 =====\n",
       "layer is falsely activated during the forward pass, *i.e.* pass *self.training* to [PyTorch's functional \n",
       "dropout](https://pytorch.org/docs/stable/nn.functional.html?highlight=dropout#torch.nn.functional.dropout)\n",
       "\n",
       "===== Document 8 =====\n",
       "- For languages with a Roman alphabet, such as English or French, the tokenizer can be used directly to \n",
       "pre-process the text inputs. The following code example runs a forward pass using the MMS-TTS English checkpoint:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from transformers import VitsTokenizer, VitsModel, set_seed\n",
       "\n",
       "tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "\n",
       "===== Document 9 =====\n",
       "Having managed to correctly load the pretrained weights into the 🤗 Transformers implementation, you should now \n",
       "make\n",
       "sure that the forward pass is correctly implemented. In [Get familiar with the original \n",
       "repository](#34-run-a-pretrained-checkpoint-using-the-original-repository), you have already created a script that \n",
       "runs a forward\n",
       "pass of the model using the original repository. Now you should write an analogous script using the 🤗 Transformers\n",
       "Backward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 1 =====\n",
       "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
       "and returns the updated parameters.\n",
       "\n",
       "===== Document 2 =====\n",
       "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
       "translates \n",
       "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
       "bandwidth-limited, and it’s typical for an activation to have to read more data in the backward than in the forward\n",
       "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
       "forward,\n",
       "\n",
       "===== Document 3 =====\n",
       "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
       "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
       "backward\n",
       "\n",
       "===== Document 4 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 5 =====\n",
       "The simplest way to try out your finetuned model for inference is to use it in a [`pipeline`]. Instantiate a \n",
       "`pipeline` for summarization with your model, and pass your text to it:\n",
       "\n",
       "```py\n",
       "&gt;&gt;&gt; from transformers import pipeline\n",
       "\n",
       "===== Document 6 =====\n",
       "```py\n",
       "&gt;&gt;&gt; from transformers import AutoTokenizer\n",
       "\n",
       "&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
       "```\n",
       "\n",
       "Then pass your text to the tokenizer:\n",
       "\n",
       "===== Document 7 =====\n",
       "The simplest way to try out your finetuned model for inference is to use it in a [`pipeline`]. Instantiate a \n",
       "`pipeline` for image classification with your model, and pass your image to it:\n",
       "\n",
       "```py\n",
       "&gt;&gt;&gt; from transformers import pipeline\n",
       "\n",
       "===== Document 8 =====\n",
       "The simplest way to try out your fine-tuned model for inference is to use it in a \n",
       "[`pipeline`](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.VideoClassificati\n",
       "onPipeline). Instantiate a `pipeline` for video classification with your model, and pass your video to it:\n",
       "\n",
       "```py\n",
       "&gt;&gt;&gt; from transformers import pipeline\n",
       "\n",
       "===== Document 9 =====\n",
       "Depending on your task, you'll typically pass the following parameters to [`Trainer`]:\n",
       "\n",
       "1. You'll start with a [`PreTrainedModel`] or a \n",
       "[`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module):\n",
       "\n",
       "   ```py\n",
       "   &gt;&gt;&gt; from transformers import AutoModelForSequenceClassification\n",
       "\n",
       "   &gt;&gt;&gt; model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
       "   ```\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "Forward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 1 =====\n",
       "4.  [ ] Created script that successfully runs forward pass using\n",
       "    original repository and checkpoint\n",
       "\n",
       "5.  [ ] Successfully opened a PR and added the model skeleton to Transformers\n",
       "\n",
       "6.  [ ] Successfully converted original checkpoint to Transformers\n",
       "    checkpoint\n",
       "\n",
       "7.  [ ] Successfully ran forward pass in Transformers that gives\n",
       "    identical output to original checkpoint\n",
       "\n",
       "8.  [ ] Finished model tests in Transformers\n",
       "\n",
       "9.  [ ] Successfully added Tokenizer in Transformers\n",
       "\n",
       "===== Document 2 =====\n",
       "model_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors=\"pt\")\n",
       "\n",
       "model(**model_inputs)  # forward pass\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "===== Document 3 =====\n",
       ">>> model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-en-ro\")\n",
       ">>> # forward pass\n",
       ">>> model(**inputs)\n",
       "```\n",
       "\n",
       "- Generation\n",
       "\n",
       "  While generating the target text set the `decoder_start_token_id` to the target language id. The following\n",
       "  example shows how to translate English to Romanian using the *facebook/mbart-large-en-ro* model.\n",
       "\n",
       "```python\n",
       ">>> from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
       "\n",
       "===== Document 4 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 5 =====\n",
       "Next, regarding the debugging strategy, there are generally a few from\n",
       "which to choose from:\n",
       "\n",
       "-   Decompose the original model into many small testable components and\n",
       "    run a forward pass on each of those for verification\n",
       "-   Decompose the original model only into the original *tokenizer* and\n",
       "    the original *model*, run a forward pass on those, and use\n",
       "    intermediate print statements or breakpoints for verification\n",
       "\n",
       "===== Document 6 =====\n",
       "Next, regarding the debugging strategy, there are generally a few from which to choose from:\n",
       "\n",
       "- Decompose the original model into many small testable components and run a forward pass on each of those for\n",
       "  verification\n",
       "- Decompose the original model only into the original *tokenizer* and the original *model*, run a forward pass on\n",
       "  those, and use intermediate print statements or breakpoints for verification\n",
       "\n",
       "===== Document 7 =====\n",
       "layer is falsely activated during the forward pass, *i.e.* pass *self.training* to [PyTorch's functional \n",
       "dropout](https://pytorch.org/docs/stable/nn.functional.html?highlight=dropout#torch.nn.functional.dropout)\n",
       "\n",
       "===== Document 8 =====\n",
       "- For languages with a Roman alphabet, such as English or French, the tokenizer can be used directly to \n",
       "pre-process the text inputs. The following code example runs a forward pass using the MMS-TTS English checkpoint:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from transformers import VitsTokenizer, VitsModel, set_seed\n",
       "\n",
       "tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
       "\n",
       "===== Document 9 =====\n",
       "Having managed to correctly load the pretrained weights into the 🤗 Transformers implementation, you should now \n",
       "make\n",
       "sure that the forward pass is correctly implemented. In [Get familiar with the original \n",
       "repository](#34-run-a-pretrained-checkpoint-using-the-original-repository), you have already created a script that \n",
       "runs a forward\n",
       "pass of the model using the original repository. Now you should write an analogous script using the 🤗 Transformers\n",
       "Backward pass info: \n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 1 =====\n",
       "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
       "and returns the updated parameters.\n",
       "\n",
       "===== Document 2 =====\n",
       "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
       "translates \n",
       "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
       "bandwidth-limited, and it’s typical for an activation to have to read more data in the backward than in the forward\n",
       "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
       "forward,\n",
       "\n",
       "===== Document 3 =====\n",
       "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
       "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
       "backward\n",
       "\n",
       "===== Document 4 =====\n",
       "```python\n",
       "from transformers import Tool\n",
       "\n",
       "\n",
       "class HFModelDownloadsTool(Tool):\n",
       "    pass\n",
       "```\n",
       "\n",
       "===== Document 5 =====\n",
       "The simplest way to try out your finetuned model for inference is to use it in a [`pipeline`]. Instantiate a \n",
       "`pipeline` for summarization with your model, and pass your text to it:\n",
       "\n",
       "```py\n",
       ">>> from transformers import pipeline\n",
       "\n",
       "===== Document 6 =====\n",
       "```py\n",
       ">>> from transformers import AutoTokenizer\n",
       "\n",
       ">>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
       "```\n",
       "\n",
       "Then pass your text to the tokenizer:\n",
       "\n",
       "===== Document 7 =====\n",
       "The simplest way to try out your finetuned model for inference is to use it in a [`pipeline`]. Instantiate a \n",
       "`pipeline` for image classification with your model, and pass your image to it:\n",
       "\n",
       "```py\n",
       ">>> from transformers import pipeline\n",
       "\n",
       "===== Document 8 =====\n",
       "The simplest way to try out your fine-tuned model for inference is to use it in a \n",
       "[`pipeline`](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.VideoClassificati\n",
       "onPipeline). Instantiate a `pipeline` for video classification with your model, and pass your video to it:\n",
       "\n",
       "```py\n",
       ">>> from transformers import pipeline\n",
       "\n",
       "===== Document 9 =====\n",
       "Depending on your task, you'll typically pass the following parameters to [`Trainer`]:\n",
       "\n",
       "1. You'll start with a [`PreTrainedModel`] or a \n",
       "[`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module):\n",
       "\n",
       "   ```py\n",
       "   >>> from transformers import AutoModelForSequenceClassification\n",
       "\n",
       "   >>> model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
       "   ```\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 0.36 seconds| Input tokens: 2,068 | Output tokens: 106]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 0.36 seconds| Input tokens: 2,068 | Output tokens: 106]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Output message of the LLM:</span> ────────────────────────────────────────────────────────────────────────────────────────\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Thought: Based on the retrieved information, the backward pass generally introduces a considerable computational </span><span style=\"background-color: #0d1117\">  </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">overhead compared to the forward pass, especially due to the need to recalculate intermediate activations and the </span><span style=\"background-color: #0d1117\"> </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">increased number of floating-point operations (flops) for certain layers like convolutions and linear layers.</span><span style=\"background-color: #0d1117\">      </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Therefore, it is reasonable to conclude that the backward pass is slower than the forward pass for a transformers </span><span style=\"background-color: #0d1117\"> </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">model training. I'll provide the final answer using the </span><span style=\"color: #a5d6ff; text-decoration-color: #a5d6ff; background-color: #0d1117\">`final_answer`</span><span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\"> tool.</span><span style=\"background-color: #0d1117\">                                       </span>\n",
       "<span style=\"background-color: #0d1117\">                                                                                                                   </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">Code:</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```py</span><span style=\"background-color: #0d1117\">                                                                                                              </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">final_answer(\"backward pass\")</span><span style=\"background-color: #0d1117\">                                                                                      </span>\n",
       "<span style=\"color: #e6edf3; text-decoration-color: #e6edf3; background-color: #0d1117\">```&lt;end_code&gt;</span><span style=\"background-color: #0d1117\">                                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mOutput message of the LLM:\u001b[0m ────────────────────────────────────────────────────────────────────────────────────────\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mThought:\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mBased\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mon\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mretrieved\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23minformation,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mgenerally\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mintroduces\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23ma\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mconsiderable\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcomputational\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m  \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23moverhead\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcompared\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mespecially\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mdue\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mneed\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mrecalculate\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mintermediate\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mactivations\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mincreased\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mnumber\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mof\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfloating-point\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23moperations\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m(flops)\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfor\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mcertain\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlayers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlike\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mconvolutions\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mand\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlinear\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mlayers.\u001b[0m\u001b[48;2;13;17;23m      \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mTherefore,\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mit\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mreasonable\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mto\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mconclude\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthat\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mbackward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mis\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mslower\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthan\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mforward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfor\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23ma\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtransformers\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[48;2;13;17;23m \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mmodel\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtraining.\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mI'll\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mprovide\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mfinal\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23manswer\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23musing\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mthe\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;165;214;255;48;2;13;17;23m`final_answer`\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mtool.\u001b[0m\u001b[48;2;13;17;23m                                       \u001b[0m\n",
       "\u001b[48;2;13;17;23m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mCode:\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```py\u001b[0m\u001b[48;2;13;17;23m                                                                                                              \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23mfinal_answer(\"backward\u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23m \u001b[0m\u001b[38;2;230;237;243;48;2;13;17;23mpass\")\u001b[0m\u001b[48;2;13;17;23m                                                                                      \u001b[0m\n",
       "\u001b[38;2;230;237;243;48;2;13;17;23m```<end_code>\u001b[0m\u001b[48;2;13;17;23m                                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"font-weight: bold\">Executing this code:</span> ──────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">1 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"backward pass\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                              </span> │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ \u001b[1mExecuting this code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m1 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbackward pass\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: backward pass</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: backward pass\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 3.36 seconds| Input tokens: 5,795 | Output tokens: 215]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 3.36 seconds| Input tokens: 5,795 | Output tokens: 215]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "backward pass\n"
     ]
    }
   ],
   "source": [
    "from smolagents import HfApiModel, CodeAgent\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[retriever_tool], model=HfApiModel(), max_iterations=4, verbose=True\n",
    ")\n",
    "agent_output = agent.run(\"For a transformers model training, which is slower, the forward or the backward pass?\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
